{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# √â prov√°vel que oi cliente receba um pagamento de seguro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents <a id='back'></a>\n",
    "\n",
    "* [Introdu√ß√£o](#intro)\n",
    "* [Etapa 1. Vis√£o geral dos dados](#data_review)\n",
    "* [Etapa 2. Modelo](#model)\n",
    "* [Etapa 3. Ofuscar Dados](#obfuscate)\n",
    "* [Conclus√µes](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A companhia de seguros Proteja Seu Amanh√£ quer resolver algumas tarefas com a ajuda de aprendizado de m√°quina e voc√™ precisa avaliar a possibilidade de faz√™-lo.\n",
    "\n",
    "- Tarefa 1: Encontrar clientes semelhantes a um determinado cliente. Isso vai ajudar os agentes da empresa com tarefas de marketing.\n",
    "- Tarefa 2: Predizer se um novo cliente provavelmente receber√° um pagamento de seguro. Um modelo de predi√ß√£o pode ser melhor do que um modelo dummy?\n",
    "- Tarefa 3: Predizer o n√∫mero de pagamentos de seguro que um novo cliente provavelmente receber√° usando um modelo de regress√£o linear.\n",
    "- Tarefa 4: Proteger os dados pessoais dos clientes sem estragar o modelo da tarefa anterior. √â necess√°rio desenvolver um algoritmo de transforma√ß√£o de dados que tornaria dif√≠cil recuperar informa√ß√µes pessoais se os dados ca√≠ssem nas m√£os erradas. Isso √© chamado de mascaramento de dados ou ofusca√ß√£o de dados. Mas os dados devem ser protegidos de forma que a qualidade dos modelos de aprendizado de m√°quina n√£o piore. Voc√™ n√£o precisa escolher o melhor modelo, s√≥ prove que o algoritmo funciona corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©-processamento de dados & Explora√ß√£o\n",
    "\n",
    "## Inicializa√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/17/1c/ccdd103cfcc9435a18819856fbbe0c20b8fa60bfc3343580de4be13f0668/scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.0 MB 4.1 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/11.0 MB 7.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 8.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.9/11.0 MB 10.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.7/11.0 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 5.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.0 MB 6.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.2/11.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.8/11.0 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.6/11.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1. Vis√£o geral dos dados <a id='data_review'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necess√°rias\n",
    "import numpy as np  # Biblioteca para opera√ß√µes matem√°ticas e manipula√ß√£o de arrays\n",
    "import pandas as pd  # Biblioteca para manipula√ß√£o e an√°lise de dados em formato tabular\n",
    "\n",
    "import seaborn as sns  # Biblioteca para visualiza√ß√£o de dados baseada no Matplotlib\n",
    "\n",
    "import sklearn.linear_model  # M√≥dulo do scikit-learn para modelos de regress√£o linear\n",
    "import sklearn.metrics  # M√≥dulo do scikit-learn para avalia√ß√£o de modelos\n",
    "import sklearn.neighbors  # M√≥dulo do scikit-learn para algoritmos de vizinhos mais pr√≥ximos\n",
    "import sklearn.preprocessing  # M√≥dulo do scikit-learn para pr√©-processamento de dados\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # Fun√ß√£o para dividir os dados em conjuntos de treino e teste\n",
    "\n",
    "from IPython.display import display  # Fun√ß√£o para exibir objetos em um formato mais elegante no Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregue os dados e fa√ßa uma verifica√ß√£o b√°sica de que est√£o livres de problemas √≥bvios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/insurance_us.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/datasets/insurance_us.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/insurance_us.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/insurance_us.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renomeamos as colunas para tornar o c√≥digo mais consistente com seu estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos querer corrigir o tipo de idade (de float para int), embora isso n√£o seja cr√≠tico\n",
    "df['age'] = df['age'].astype('int')\n",
    "# escreva sua convers√£o aqui se voc√™ escolher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifique se a convers√£o foi bem-sucedida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora d√™ uma olhada nas estat√≠sticas descritivas dos dados.\n",
    "# Parece que est√° tudo bem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar rapidamente se existem determinados grupos de clientes observando o gr√°fico de pares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df, kind='hist')\n",
    "g.fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, √© um pouco dif√≠cil identificar grupos √≥bvios (clusters), pois √© dif√≠cil combinar v√°rias vari√°veis simultaneamente (para analisar distribui√ß√µes multivariadas). √â a√≠ que √Ålgebra Linear e Aprendizado de M√°quina podem ser bastante √∫teis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 1. Clientes Similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na linguagem de AM, √© necess√°rio desenvolver um procedimento que retorne k vizinhos mais pr√≥ximos (objetos) para um determinado objeto com base na dist√¢ncia entre os objetos.\n",
    "Voc√™ pode querer rever as seguintes li√ß√µes (cap√≠tulo -> li√ß√£o)- Dist√¢ncia Entre Vetores -> Dist√¢ncia Euclidiana\n",
    "- Dist√¢ncia Entre Vetores -> Dist√¢ncia de Manhattan\n",
    "\n",
    "Para resolver a tarefa, podemos tentar diferentes m√©tricas de dist√¢ncia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escreva uma fun√ß√£o que retorne k vizinhos mais pr√≥ximos para um n-√©simo objeto com base em uma m√©trica de dist√¢ncia especificada. O n√∫mero de pagamentos de seguro recebidos n√£o deve ser levado em considera√ß√£o para esta tarefa. \n",
    "\n",
    "Voc√™ pode usar uma implementa√ß√£o pronta do algoritmo kNN do scikit-learn (verifique [o link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)) ou usar a sua pr√≥pria.\n",
    "Teste-o para quatro combina√ß√µes de dois casos\n",
    "- Escalabilidade\n",
    "  - os dados n√£o s√£o escalados\n",
    "  - os dados escalados com o escalonador [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html) \n",
    "- M√©tricas de dist√¢ncia\n",
    "  - Euclidiana\n",
    "  - Manhattan\n",
    "\n",
    "Responda √†s perguntas:\n",
    "- Os dados n√£o escalados afetam o algoritmo kNN? Se sim, como isso acontece?\n",
    "-Qu√£o semelhantes s√£o os resultados usando a m√©trica de dist√¢ncia de Manhattan (independentemente da escalabilidade)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(df, n, k, metric):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retorna os vizinhos mais pr√≥ximos de k\n",
    "\n",
    "    :param df: DataFrame pandas usado para encontrar objetos semelhantes dentro de    \n",
    "    :param n: n√∫mero do objeto pelo qual os vizinhos mais pr√≥ximos s√£o procurados\n",
    "    :param k: o n√∫mero dos vizinhos mais pr√≥ximos a serem retornados\n",
    "    :param metric: nome da m√©trica de dist√¢ncia    \"\"\"\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=k,metric=metric).fit(df[feature_names])\n",
    "    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)\n",
    "    \n",
    "    df_res = pd.concat([\n",
    "        df.iloc[nbrs_indices[0]], \n",
    "        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])\n",
    "        ], axis=1)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']\n",
    "\n",
    "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos obter registros semelhantes para um determinado registro para cada combina√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df, 1, 5, \"manhattan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df_scaled, 1, 5, \"manhattan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_knn(df, 1, 5, \"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df_scaled, 1, 5, \"euclidean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respostas para as perguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Os dados n√£o escalados afetam o algoritmo kNN? Se sim, como isso acontece?** \n",
    "\n",
    "Sim, afetam a imprescindibilidade, podendo ocasionar em erros de predi√ß√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qu√£o semelhantes s√£o os resultados usando a m√©trica de dist√¢ncia de Manhattan (independentemente da escalabilidade)?** \n",
    "√â menos preciso das demais, gerando grande distancia entre os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 2. √â prov√°vel que o cliente receba um pagamento do seguro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em termos de aprendizado de m√°quina, podemos olhar para isso como uma tarefa de classifica√ß√£o bin√°ria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os pagamentos de seguro sendo mais do que zero como objetivo, avalie se a abordagem da classifica√ß√£o kNN pode ser melhor do que um modelo dummy.\n",
    "\n",
    "Instru√ß√µes:\n",
    "- Construa um classificador baseado em kNN e me√ßa sua qualidade com a m√©trica F1 para k=1..10 tanto para os dados originais quanto para os escalados. Seria interessante ver como k pode influenciar a m√©trica de avalia√ß√£o e se a escalabilidade dos dados faz alguma diferen√ßa. Voc√™ pode usar uma implementa√ß√£o pronta do algoritmo de classifica√ß√£o kNN do scikit-learn (verifique [o link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) ou usar a sua pr√≥pria.\n",
    "- Construa o modelo dummy, que √© aleat√≥rio para este caso. Deve retornar com alguma probabilidade o valor \"1\". LVamos testar o modelo com quatro valores de probabilidade: 0, a probabilidade de fazer qualquer pagamento de seguro, 0,5, 1.\n",
    "\n",
    "A probabilidade de fazer qualquer pagamento de seguro pode ser definida como\n",
    "\n",
    "$$\n",
    "P\\{\\text{pagamento de seguro recebido}= n√∫mero de clientes que receberam qualquer pagamento de seguro}}{\\text{n√∫mero total de clientes}}.\n",
    "$$\n",
    "\n",
    "Divida os dados inteiros na propor√ß√£o 70:30 para as partes de treinamento/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcule a meta\n",
    "df['insurance_benefits_received'] = df['insurance_benefits'].sum()/df['insurance_benefits'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# verifique o desequil√≠brio de classe com value_counts()\n",
    "df['insurance_benefits']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituindo valores maiores de 1 em 1\n",
    "df['insurance_benefits'] = df['insurance_benefits'].mask(df['insurance_benefits'] > 1, 1)\n",
    "df_scaled['insurance_benefits'] = df_scaled['insurance_benefits'].mask(df_scaled['insurance_benefits'] > 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['insurance_benefits'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['insurance_benefits'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['insurance_benefits_received'] = df['insurance_benefits'].sum()/df['insurance_benefits'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['insurance_benefits_received'] = df_scaled['insurance_benefits'].sum()/df_scaled['insurance_benefits'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(y_true, y_pred):\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "    print(f'F1: {f1_score:.2f}')\n",
    "    \n",
    "# se voc√™ tiver um problema com a linha a seguir, reinicie o kernel e execute o caderno novamente\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print('Matriz de Confus√£o')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['insurance_benefits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando sa√≠da de um modelo aleat√≥rio\n",
    "\n",
    "def rnd_model_predict(P, size, seed=42):\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    return rng.binomial(n=1, p=P, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for P in [0, df['insurance_benefits'].sum() / len(df), 0.5, 1]:\n",
    "\n",
    "    print(f'A probabilidade: {P:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(P,5000)\n",
    "        \n",
    "    eval_classifier(df['insurance_benefits'], y_pred_rnd)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for P in [0, df_scaled['insurance_benefits'].sum() / len(df), 0.5, 1]:\n",
    "\n",
    "    print(f'A probabilidade: {P:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(P,5000)\n",
    "        \n",
    "    eval_classifier(df_scaled['insurance_benefits'], y_pred_rnd)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos dados escalados e n√£o escalados podemos ver um resultado id√™ntico. O resultado mais plaus√≠vel seria o de 50% de probabilidade sendo seu F1 de 0.20 com a matrix de confus√£o melhor distribuida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2. Modelo <a id='model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 3. Regress√£o (com Regress√£o Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os pagamentos de seguro como objetivo, avalie qual seria o REQM para um modelo de Regress√£o Linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construa sua pr√≥pria implementa√ß√£o de Regress√£o Linear. Para isso, lembre-se de como a solu√ß√£o da tarefa de regress√£o linear √© formulada em termos de √Ålgebra linear. Verifique o REQM para os dados originais e os escalados. Voc√™ pode ver alguma diferen√ßa no REQM entre esses dois casos?\n",
    "\n",
    "Vamos denotar\n",
    "- $X$ ‚Äî matriz de caracter√≠sticas, cada linha √© um caso, cada coluna √© uma caracter√≠stica, a primeira coluna consiste em unidades\n",
    "- $y$ ‚Äî objetivo (um vetor)\n",
    "- $\\hat{y}$ ‚Äî objetivo estimado (um vetor)- $w$ ‚Äî vetor de peso\n",
    "\n",
    "A tarefa de regress√£o linear na linguagem de matrizes pode ser formulada como\n",
    "$$\n",
    "y = Xw\n",
    "$$\n",
    "\n",
    "O objetivo do treinamento, ent√£o, √© encontrar os $w$ que minimizaria a dist√¢ncia L2 (EQM) entre $Xw$ e $y$:\n",
    "\n",
    "$$\n",
    "\\min_w d_2(Xw, y) \\quad \\text{or} \\quad \\min_w \\text{MSE}(Xw, y)\n",
    "$$\n",
    "\n",
    "Parece que h√° uma solu√ß√£o anal√≠tica para a quest√£o acima:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "A f√≥rmula acima pode ser usada para encontrar os pesos $w$ e o √∫ltimo pode ser usado para calcular valores preditos\n",
    "\n",
    "$$\n",
    "\\hat{y} = X_{val}w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividi todos os dados na propor√ß√£o 70:30 para as partes de treinamento/valida√ß√£o. Usei a m√©trica REQM para a avalia√ß√£o do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # somando as unidades\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        self.weights = np.linalg.inv(X2.T.dot(X2)).dot(X2.T).dot(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # somando as unidades\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1).dot(self.weights)\n",
    "        return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regressor(y_true, y_pred):\n",
    "    \n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'REQM: {rmse:.2f}')\n",
    "    \n",
    "    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "    print(f'R2: {r2_score:.2f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_test, y_test)\n",
    "print(lr.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um modelo de regress√£o Linear com REQM de 0.23 e um R2 de 0.66."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 4. Ofuscando dados<a id='obfuscate'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
    "df_pn = df[personal_info_column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pn.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando uma matriz $P$ aleat√≥ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando se a matriz $P$ √© invert√≠vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi = np.linalg.inv(P)\n",
    "Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi @ P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voc√™ consegue adivinhar a idade ou a renda dos clientes ap√≥s a transforma√ß√£o?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√£o, pois os dados est√£o ofuscados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = X.dot(P)\n",
    "\n",
    "print(X3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupendando os dados ofuscados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xof = (X3.dot(Pi))\n",
    "Xof\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimindo todos os tr√™s casos para alguns clientes- Os dados originais\n",
    "- O transformado\n",
    "- O invertido (recuperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Os dados originais\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O transformado\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O invertido (recuperado)\n",
    "Xof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores de 0 foram os mais afetados, dado o ofuscamento esses valores quando s√£o multiplicados pela matrix invert√≠vel ùëÉ. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de regress√£o linear com ofusca√ß√£o de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos provar que a Regress√£o Linear pode funcionar computacionalmente com a transforma√ß√£o de ofusca√ß√£o escolhida.\n",
    "Crie um procedimento ou uma classe que execute a Regress√£o Linear opcionalmente com a ofusca√ß√£o. Voc√™ pode usar uma implementa√ß√£o pronta de Regress√£o Linear do scikit-learn ou sua pr√≥pria.\n",
    "\n",
    "Execute a Regress√£o Linear para os dados originais e os ofuscados, compare os valores previstos e os valores da m√©trica $R^2$ do REQM. H√° alguma diferen√ßa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedimento**\n",
    "\n",
    "- Crie uma matriz quadrada $P$ de n√∫meros aleat√≥rios.\n",
    "- Verifique se √© invert√≠vel. Caso contr√°rio, repita o primeiro ponto at√© obtermos uma matriz invert√≠vel.\n",
    "- Use $XP$ como a nova matriz de caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rngtest = np.random.default_rng(seed=36)\n",
    "P = rngtest.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi = np.linalg.inv(P)\n",
    "Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegressionOvershadowed:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = None\n",
    "    \n",
    "    def fitovershadowed(self, X, y):\n",
    "        \n",
    "        # somando as unidades\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        self.weights = np.linalg.inv((X2@P).T.dot(X2@P)).dot((X2@P).T).dot(y)\n",
    "\n",
    "    def predictovershadowed(self, X):\n",
    "        \n",
    "        # somando as unidades\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1).dot(self.weights)\n",
    "        return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrOvershadowed = MyLinearRegression()\n",
    "\n",
    "lrOvershadowed.fit(X_train, y_train)\n",
    "print(lrOvershadowed.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrOvershadowed.fit(X_test, y_test)\n",
    "print(lr.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predlrOvershadowed = lrOvershadowed.predict(X_test)\n",
    "eval_regressor(y_test, y_test_predlrOvershadowed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos os mesmo resultados do que os dados n√£o ofuscados, quer dizer que nosso trabalho foi conclu√≠do corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o geral <a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto, importamos bibliotecas como \"pandas\" e \"numpy\" que habitualmente j√° utilizamos, sklearn para cria√ß√£o do nosso modelo, \"Seaborn\" para representa√ß√£o em gr√°ficos.\n",
    "\n",
    "Realizamos o pre-processamento, para que n√£o tivesse acontecido algum problema na cria√ß√£o do nosso modelo.\n",
    "\n",
    "Usamos o algoritimo KNN para procurar clientes similares, com auxilio das m√©tricas Dist√¢ncia Euclidiana e Dist√¢ncia Manhattan, trabalhamos com os dados escalados e n√£o escalados para ter melhor visualiza√ß√£o e precis√£o em nossa predi√ß√£o. Desenvolvemos um prot√≥tipo de um modelo de aprendizado de m√°quina para saber se √© prov√°vel que o cliente receba um pagamento do seguro, com a probalidade de 50% e um F1: 0.20 como a melhor alternativa, aplicamos uma regress√£o Linear com REQM: 0.23 R2: 0.66 com os dados ofuscados e n√£o ofuscados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "√çndice",
   "title_sidebar": "Conte√∫dos ",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
